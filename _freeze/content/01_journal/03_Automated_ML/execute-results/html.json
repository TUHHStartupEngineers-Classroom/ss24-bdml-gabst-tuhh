{
  "hash": "80e38aa60843c3fdde9b7dc1844721ae",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Automated ML\"\ndate: \"06/16/2024\"\nauthor: \"Gabriel Storch\"\n    \noutput: \n    html_document:\n        toc: TRUE\n        theme: flatly\n        highlight: tango\n        code_folding: hide\n        df_print: paged\neditor: \n  markdown: \n    wrap: 72\n\n---\n\n# First Assignment Auto ML:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(h2o)\nlibrary(rsample)\nlibrary(cowplot)\nlibrary(glue)\n```\n:::\n\n\nReading data for analysis\n\n::: {.cell}\n\n```{.r .cell-code}\nemployee_attrition_tbl <- read_csv(\"C:/Projekte/bdml/employee_data.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Rows: 1470 Columns: 35\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\n#> dbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nemployee_attrition_tbl %>%\n    select(Attrition, MonthlyIncome, PercentSalaryHike, StockOptionLevel, EnvironmentSatisfaction, WorkLifeBalance, JobInvolvement, OverTime, TrainingTimesLastYear, YearsAtCompany, YearsSinceLastPromotion) %>%\n    ggpairs(aes(color = Attrition), lower = \"blank\", legend = 1,\n            diag  = list(continuous = wrap(\"densityDiag\", alpha = 0.5))) +\n    theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](03_Automated_ML_files/figure-html/unnamed-chunk-3-1.png){width=1440}\n:::\n:::\n\nI present the asnwers by Number. Answer\n\n1.Those that are leaving have a lower Monthly Income.\n\n2. It's difficult to deduce anything based on the visualization.\n\n3. Those that are staying have a higher stock option level. This is not true for the highest stock option level tho.\n\n4. A higher proportion of those leaving have a low environment satisfaction level\n\n5. Those that are staying have a higher density of 2's and 3's\n\n6. Those that are leaving have a lower density of 3's and 4's\n\n7. The proportion of those leaving that are working Over Time are high compared to those that are not leaving. (roughly 50% of those who are leaving are doing OT, vs ~25% for stayers)\n\n8. It's difficult to deduce anything based on the visualization.\n\n9. People that leave tend to have less working years at the company\n\n10. It's difficult to deduce anything based on the visualization\n\n\n# Second Assignment Auto ML:\nLoading, splitting train + test\n\n\n::: {.cell}\n\n```{.r .cell-code}\nback_order_data <- read_csv(\"C:/Projekte/bdml/back_order_data.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nback_order_data$went_on_backorder <-  as.factor(back_order_data$went_on_backorder)\nback_order_data$deck_risk <- ifelse(back_order_data$deck_risk == \"Yes\", 1, 0)\nback_order_data$potential_issue <- ifelse(back_order_data$potential_issue == \"Yes\", 1, 0)\nback_order_data$oe_constraint <- ifelse(back_order_data$oe_constraint == \"Yes\", 1, 0)\nback_order_data$ppap_risk <- ifelse(back_order_data$ppap_risk == \"Yes\", 1, 0)\nback_order_data$stop_auto_buy <- ifelse(back_order_data$stop_auto_buy == \"Yes\", 1, 0)\nback_order_data$rev_stop <- ifelse(back_order_data$rev_stop == \"Yes\", 1, 0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit_obj                       <- rsample::initial_split(back_order_data, prop = 0.8)\ntrain_tbl              <- training(split_obj)\ntest_tbl               <- testing(split_obj)\n\n# Modeling\nh2o.init()\n\n# Split data into a training and a validation data frame\n\ntrain_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)[[1]]\nvalid_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n```\n:::\n\nSpecifying response & predictors, training\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresponse <- \"went_on_backorder\"\n\npredictors <-  setdiff(names(train_h2o), response)\n\nautoml_models_h2o <- h2o.automl(\n  x = predictors,\n  y = response,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  nfolds            = 5,\n  max_runtime_secs = 120\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard\n#1\tStackedEnsemble_AllModels_3_AutoML_1_20240620_182822\t0.9496856\t0.1743012\t\n#2\tStackedEnsemble_BestOfFamily_3_AutoML_1_20240620_182822\t0.9482406\t0.1758886\t\n#3\tStackedEnsemble_BestOfFamily_4_AutoML_1_20240620_182822\t0.9480737\t0.1765624\t\n#4\tStackedEnsemble_AllModels_2_AutoML_1_20240620_182822\t0.9480019\t0.1761713\t\n#5\tGBM_grid_1_AutoML_1_20240620_182822_model_21\t0.9477282\t0.1771441\t\n#6\tStackedEnsemble_BestOfFamily_2_AutoML_1_20240620_182822\t0.9474604\t0.1767916\n```\n:::\n\nPredicting using the leader model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh2o.predict(automl_models_h2o@leader, newdata = test_h2o)\n\n#predict  No      Yes\n#<fctr>   <dbl>   <dbl>\n#1\tYes\t0.09254812\t0.9074519\t\n#2\tNo\t0.79122599\t0.2087740\t\n#3\tYes\t0.31921248\t0.6807875\t\n#4\tNo\t0.55546408\t0.4445359\t\n#5\tYes\t0.22277649\t0.7772235\t\n#6\tNo\t0.83505847\t0.1649415\t\n```\n:::\n\nsaving the leader model\n\n::: {.cell}\n\n```{.r .cell-code}\npath <- h2o.saveModel(automl_models_h2o@leader, path = \"models/\")\n```\n:::\n\n\n# Third Assignment Auto ML: Performance Measures\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_transformed_tbl <- automl_models_h2o@leaderboard %>%\n        as_tibble() %>%\n        select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n        mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n        slice(1:15) %>% \n        rownames_to_column(var = \"rowname\") %>%\n        # Visually this step will not change anything\n        # It reorders the factors under the hood\n        mutate(\n          model_id   = as_factor(model_id) %>% reorder(auc),\n          model_type = as.factor(model_type)\n          ) %>% \n          pivot_longer(cols = -c(model_id, model_type, rowname), \n                       names_to = \"key\", \n                       values_to = \"value\", \n                       names_transform = list(key = forcats::fct_inorder)\n                       ) %>% \n        mutate(model_id = paste0(rowname, \". \", model_id) %>% as_factor() %>% fct_rev())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_transformed_tbl %>%\n        ggplot(aes(value, model_id, color = model_type)) +\n        geom_point(size = 3) +\n        geom_label(aes(label = round(value, 2), hjust = \"inward\")) +\n        \n        # Facet to break out logloss and auc\n        facet_wrap(~ key, scales = \"free_x\") +\n        labs(title = \"Leaderboard Metrics\",\n             subtitle = paste0(\"Ordered by: \", \"auc\"),\n             y = \"Model Postion, Model ID\", x = \"\") + \n        theme(legend.position = \"bottom\")\n```\n:::\n\n![Leaderboard Metrics](leadboardmetrics.png)\n\nYou can see that the models where able to predict reorder very well with an auc of 0.95 and a logloss of 0.16. This is achieved by Stacked Ensemble across the top 1000 Models trained. Interestingly, the only model types in the Leaderboard are GBM and StackedEnsemble. The differences between the models in the leaderboard are very much marginal.\n\n## Grid Search Tuning\nMaybe I can squeeze half a percent more out of my best GBM (stackedensemble cant be used in grid search in h2o):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- h2o.getModel(\"GBM_grid_1_AutoML_14_20240620_131005_model_20\")\nh2o.performance(model, test_h2o)\n```\n:::\n\n## grid search\n\n\n::: {.cell}\n\n```{.r .cell-code}\nensemble_grid <- h2o.grid(algorithm = \"gbm\",\n                          grid_id = \"gbmgrid\",\n                          x=predictors, y = response, training_frame = train_h2o, validation_frame = valid_h2o, nfolds = 5,\n                          hyper_params = list(ntrees = list(50, 100, 125, 200),\n                                              max_depth = list(8, 10, 15, 20),\n                                              min_rows = list(2, 5, 10, 20),\n                                              sample_rate= list(0.5, 0.75)\n                            )\n                          )\n \n \n#max_depth min_rows ntrees sample_rate model_ids logloss\n#<chr>    <chr>  <chr> <chr> <chr> <chr>\n#228\t20.00000\t2.00000\t125.00000\t0.75000\tgbmgrid_model_221\t0.31673\n#229\t15.00000\t2.00000\t200.00000\t0.50000\tgbmgrid_model_172\t0.31903\n#230\t20.00000\t5.00000\t200.00000\t0.75000\tgbmgrid_model_241\t0.32009\n#231\t15.00000\t2.00000\t200.00000\t0.75000\tgbmgrid_model_236\t0.35177\n#232\t20.00000\t2.00000\t200.00000\t0.50000\tgbmgrid_model_173\t0.40970\n#233\t20.00000\t2.00000\t200.00000\t0.75000\tgbmgrid_model_237\t0.44275\n```\n:::\n\nLooks like the model automl returned was already achieving better log loss than my tuning attempt.\n\n## roc plot, precision + recall plot\n\ndefining functions for everything..\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_roc <- function(model_metrics_tbl, order_by, size = 1.5) {\n  order_by_expr <- rlang::sym(order_by)\n  model_metrics_tbl %>%\n        ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n        theme(legend.direction = \"vertical\") \n}\n\nplot_prec_rec <- function(model_metrics_tbl, order_by, size = 1.5) {\n    order_by_expr <- rlang::sym(order_by)\n  model_metrics_tbl %>%\n        ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n        theme(legend.position = \"none\") \n}\n\nplot_gain <- function(gain_lift_tbl, order_by, size = 1.5) {\n    order_by_expr <- rlang::sym(order_by)\n    gain_lift_tbl %>%\n        ggplot(aes(cumulative_data_fraction, gain, \n                          color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size,) +\n        geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                     color = \"red\", size = size, linetype = \"dotted\") +\n        expand_limits(x = c(0, 1), y = c(0, 1)) +\n        labs(title = \"Gain\",\n             x = \"Cumulative Data Fraction\", y = \"Gain\") +\n        theme(legend.position = \"none\")\n}\n\nplot_lift <- function(gain_lift_tbl, order_by, size = 1.5) {\n      order_by_expr <- rlang::sym(order_by)\n    gain_lift_tbl %>%\n        ggplot(aes(cumulative_data_fraction, lift, \n                          color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                     color = \"red\", size = size, linetype = \"dotted\") +\n        expand_limits(x = c(0, 1), y = c(0, 1)) +\n        labs(title = \"Lift\",\n             x = \"Cumulative Data Fraction\", y = \"Lift\") +\n        theme(legend.position = \"none\") \n    \n}\nget_model_metrics <- function(leaderboard_tbl, order_by,  test_tbl = test_tbl) {\n  order_by_expr <- rlang::sym(order_by)\n  n <- nrow(leaderboard_tbl)\n  metrics_list <- list()\n  \n  for (i in 1:n) {\n    model_id <- leaderboard_tbl$model_id[i]\n    model_metrics <- get_model_performance_metrics(model_id, test_tbl)\n    metrics_list[[i]] <- model_metrics\n  }\n  \n  leaderboard_tbl$metrics <- metrics_list\n  unnest(leaderboard_tbl, cols = metrics) %>%\n    mutate(\n      model_id = as_factor(model_id) %>% \n                  fct_reorder(!! order_by_expr, .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n      auc      = auc %>% \n                  round(3) %>% \n                  as.character() %>% \n                  as_factor() %>% \n                  fct_reorder(as.numeric(model_id)),\n      logloss  = logloss %>% \n                  round(4) %>% \n                  as.character() %>% \n                  as_factor() %>% \n                  fct_reorder(as.numeric(model_id))\n    )\n}\n\nget_model_performance_metrics <- function(model_id, test_tbl) {\n    model_h2o <- h2o.getModel(model_id)\n  tst_h2o <- as.h2o(test_tbl)\n  perf_h2o <- h2o.performance(model_h2o, newdata = tst_h2o)\n  \n  metrics_df <- perf_h2o %>% h2o.metric() %>% as_tibble() %>%\n    select(threshold, tpr, fpr, precision, recall)\n  \n  return(metrics_df)\n}\n```\n:::\n\n\n# Plotting ROC\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmax_models <- 3\nleaderboard_tbl <- automl_models_h2o@leaderboard %>%\n        as_tibble() %>%\n        slice(1:max_models)\nmodel_metrics <- get_model_metrics(leaderboard_tbl, \"logloss\", test_tbl)\nplot_roc(model_metrics, \"logloss\")\n```\n:::\n\n![ROC Plot](roc.png)\nThe models are too close to each other to see a meaningful difference.\n\n# Plotting Precision vs. Recall and best limit\n\n::: {.cell}\n\n```{.r .cell-code}\nmetrics_tbl <- get_model_performance_metrics(\"StackedEnsemble_AllModels_3_AutoML_1_20240620_182822\", test_tbl)\n# optimality: threshold is at highest sum of both\n# the use case means precision and recall are both important.\noptimal_threshold <- metrics_tbl %>%\n  filter(precision + recall == max(precision + recall)) %>%\n  pull(threshold)\n\n\nggplot(metrics_tbl, aes(x = recall, y = precision)) +\n  geom_line() +\n  geom_vline(xintercept = metrics_tbl$recall[metrics_tbl$threshold == optimal_threshold], linetype = \"dashed\") +\n  geom_point(x = metrics_tbl$recall[metrics_tbl$threshold == optimal_threshold], \n             y = metrics_tbl$precision[metrics_tbl$threshold == optimal_threshold], \n             color = \"red\", size = 3) +\n  labs(title = \"Precision-Recall Trade-off\", x = \"Recall\", y = \"Precision\") +\n  theme_minimal()\n```\n:::\n\n![Precision Recall Tradeoff Plot](prtradeoff.png)\n# precision/recall plot for leaderboard\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_prec_rec(model_metrics, \"logloss\")\n```\n:::\n\n![Precision VS Recall Plot](precrecplot.png)\n# Gain plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    get_gain_lift <- function(model_id, test_tbl) {\n        \n        model_h2o <- h2o.getModel(model_id)\n        perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n        \n        perf_h2o %>%\n            h2o.gainsLift() %>%\n            as.tibble() %>%\n            select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n        \n        \n    }\nget_gain_lift_table <- function(leaderboard_tbl, order_by, test_tbl) {\n    order_by_expr <- rlang::sym(order_by)\n    leaderboard_tbl %>%\n        mutate(metrics = map(model_id, get_gain_lift, test_tbl)) %>%\n        unnest(cols = metrics) %>%\n        mutate(\n            model_id = as_factor(model_id) %>% \n                fct_reorder(!! order_by_expr, \n                            .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n            auc  = auc %>% \n                round(3) %>% \n                as.character() %>% \n                as_factor() %>% \n                fct_reorder(as.numeric(model_id)),\n            logloss = logloss %>% \n                round(4) %>% \n                as.character() %>% \n                as_factor() %>% \n                fct_reorder(as.numeric(model_id))\n        ) %>%\n        rename(\n            gain = cumulative_capture_rate,\n            lift = cumulative_lift\n        ) \n  }\n\ngain_lift_table <- get_gain_lift_table(leaderboard_tbl, \"logloss\", test_tbl)\nplot_gain(gain_lift_table, \"logloss\")\n```\n:::\n\n![Gain Plot](gainplot.png)\n# lift plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_lift(gain_lift_table, \"logloss\")\n```\n:::\n\n![Lift Plot](liftplot.png)\n# Dashboard with cow\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n    \n    # Inputs\n    \n    leaderboard_tbl2 <- h2o_leaderboard %>%\n        as_tibble() %>%\n        slice(1:max_models)\n    \n    newdata_tbl <- newdata %>%\n        as_tibble()\n    \n    # Selecting the first, if nothing is provided\n    order_by  <- tolower(order_by[[1]]) \n    \n    # Convert string stored in a variable to column name (symbol)\n    order_by_expr <- rlang::sym(order_by)\n\n    # Turn of the progress bars ( opposite h2o.show_progress())\n    h2o.no_progress()\n    \n    # 1. Model metrics\n    \n\n    model_metrics_tbl <- get_model_metrics(leaderboard_tbl2, order_by, newdata_tbl)\n    \n    \n    # 1A. ROC Plot\n    \n    p1 <- plot_roc(model_metrics_tbl, order_by_expr, size)\n        \n    \n    # 1B. Precision vs Recall\n    \n    p2 <- plot_prec_rec(model_metrics_tbl, order_by_expr, size)\n    \n    \n    # 2. Gain / Lift\n    \n    \n    gain_lift_tbl <- get_gain_lift_table(leaderboard_tbl2, order_by = order_by, test_tbl =newdata_tbl)\n    \n    # 2A. Gain Plot\n    \n    p3 <- plot_gain(gain_lift_tbl, order_by_expr, size)\n    # 2B. Lift Plot\n    \n    p4 <- plot_lift(gain_lift_tbl, order_by_expr, size)\n    \n    \n    # Combine using cowplot\n    \n    # cowplot::get_legend extracts a legend from a ggplot object\n    p_legend <- get_legend(p1)\n    # Remove legend from p1\n    p1 <- p1 + theme(legend.position = \"none\")\n    \n    # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n    p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n    \n    # cowplot::ggdraw() sets up a drawing layer\n    p_title <- ggdraw() + \n    \n    # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n    draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n               color = \"#2C3E50\")\n    \n    p_subtitle <- ggdraw() + \n        draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n                   color = \"#2C3E50\")\n    \n    # Combine everything\n    ret <- plot_grid(p_title, p_subtitle, p, p_legend, \n    \n                     # Adjust the relative spacing, so that the legends always fits\n                     ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n    \n    h2o.show_progress()\n    \n    return(ret)\n    \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_h2o_performance(automl_models_h2o@leaderboard, test_tbl, \"logloss\")\n```\n:::\n\n![Dashboard mit COW](h2omodelmetrics.png)\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}