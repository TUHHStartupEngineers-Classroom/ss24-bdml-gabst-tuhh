{
  "hash": "714f87966c27bc04df4ad6cc15c33b05",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Supervised Machine Learning\"\ndate: \"06/16/2024\"\nauthor: \"Gabriel Storch\"\noutput: \n    html_document:\n        toc: TRUE\n        theme: flatly\n        highlight: tango\n        code_folding: hide\n        df_print: paged\neditor: \n  markdown: \n    wrap: 72\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nlibrary(parsnip)\n\nlibrary(recipes)\nlibrary(rsample)\n\n\nlibrary(yardstick)\n\n\nlibrary(rpart.plot)\nlibrary(workflows)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbike_features_tbl <- readRDS(\"C:/Projekte/bdml/bike_features_tbl.rds\") %>% select(model:url)\nsplit_obj <- initial_split(bike_features_tbl, prop = 0.8, strata=\"category_2\") \n\n\ntrain_tbl <- training(split_obj)\ntest_tbl <- testing(split_obj)\n\ntrain_tbl <- train_tbl %>% set_names(str_replace_all(names(train_tbl), \" |-\", \"_\"))\ntest_tbl  <- test_tbl  %>% set_names(str_replace_all(names(test_tbl),  \" |-\", \"_\"))\n```\n:::\n\n# Problem definition\n\nWhich Bike Categories are in high demand?\nWhich Bike Categories are under represented?\n# Goal\n\nUse a pricing algorithm to determine a new product price in a category gap\n\n\nI. Build a model\n\n::: {.cell}\n\n```{.r .cell-code}\nLM <- linear_reg() %>%\n  set_engine(\"lm\")\n```\n:::\n\n\nII. Create features with the recipes package\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe_obj <- recipe(price ~ ., data = train_tbl) %>% \n                step_rm(url) %>% \n                step_dummy(all_nominal(), one_hot = TRUE ) %>%\n  step_scale(all_numeric(), -all_outcomes())\n```\n:::\n\n\n\n\nIII. Bundle the model and recipe with the workflow package\n\n::: {.cell}\n\n```{.r .cell-code}\nwf <- workflow() %>%\n   # Add the recipe to the workflow\n  add_recipe(recipe_obj) %>% \n  # add model\n  add_model(LM) %>%\n  # train model\n  fit(data = train_tbl)\n```\n:::\n\n\n\nIV. Evaluate your model with the yardstick package\n\n::: {.cell}\n\n```{.r .cell-code}\ncount <- 0\ncalc_metrics <- function(model, model_type = count, new_data = test_tbl) {\n    count <- count + 1\n\n    res <- model %>%\n        predict(new_data = new_data) %>%\n\n        bind_cols(new_data %>% select(price)) %>%\n        yardstick::metrics(truth = price, estimate = .pred) \n\n    res <- res %>% mutate(.estimator = model_type)\n\n  \n    return (res)\n\n}\ncalc_metrics(wf, new_data = test_tbl)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning: ! There are new levels in a factor: `Aeroad CF SL Disc 8.0 ETAP`, `Aeroad WMN\n#>   CF SL 8.0`, `Endurace AL 6.0`, `Endurace WMN AL 6.0`, `Endurace CF 8.0`,\n#>   `Speedmax CF SLX 9.0 LTD`, `Speedmax CF SLX 9.0 SL`, `Ultimate CF SLX Disc\n#>   9.0 Di2`, `Ultimate WMN CF SLX Disc 9.0 ETAP`, `Ultimate WMN CF SL Disc 8.0\n#>   ETAP`, `Ultimate WMN CF SL Disc 7.0`, `Ultimate CF SL 7.0`, `Ultimate CF SLX\n#>   Disc 9.0 Team Movistar`, `Ultimate CF SL Disc 8.0 Di2`, `Ultimate CF SL Disc\n#>   7.0`, `Exceed CF SLX 8`, `Exceed CF SLX 9.0`, `Grail CF SLX 8 Di2`, â€¦,\n#>   `Roadlite 5`, and `Roadlite AL 7.0`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n#> Warning in predict.lm(object = object$fit, newdata = new_data, type =\n#> \"response\", : prediction from rank-deficient fit; consider predict(.,\n#> rankdeficient=\"NA\")\n```\n\n\n:::\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"1\",\"3\":\"644.5728\"},{\"1\":\"rsq\",\"2\":\"1\",\"3\":\"1.0000\"},{\"1\":\"mae\",\"2\":\"1\",\"3\":\"470.6207\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nV. Comparing two models in the pipeline:\nmake pipeline into function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrun_complete_pipe <- function(model, model_type,  recipe = recipe_obj, train_data = train_tbl, test_data = test_tbl) {\n  wf <- workflow() %>%\n   # Add the recipe to the workflow\n  add_recipe(recipe) %>% \n  # add model\n  add_model(model) %>%\n  # train model\n  fit(data = train_data)\n  # evaluate model\n  metrics <- calc_metrics(wf, model_type,  test_data)\n  return (metrics)\n}\n```\n:::\n\nmake for loop wrapper for pipe function:\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_results <- function(models) {\n  results <- list()\nfor (mod in models) {\n  results[[length(results) + 1]] <- run_complete_pipe(mod, mod$engine, recipe_obj, train_tbl, test_tbl)\n}\n\nresults_combined <- bind_rows(\n  map_dfr(results, ~ {\n    tibble(\n      model_type = .x$.estimator,\n      rmse = filter(.x, .metric == \"rmse\")$.estimate[1],\n      rsq = filter(.x, .metric == \"rsq\")$.estimate[1],\n      mae = filter(.x, .metric == \"mae\")$.estimate[1]\n    )\n  })\n) %>%\n  distinct()\n\nresults_combined\n}\n```\n:::\n\n\nDefine some models and run the comparison\n\n::: {.cell}\n\n```{.r .cell-code}\nXGBOOST <-  boost_tree(\n  mode = \"regression\",\n  trees = 200,         \n  learn_rate = 0.01,\n  loss_reduction = 0.01\n) %>%\n  set_engine(\"xgboost\")\n\nGLMNET <- linear_reg(mode  = \"regression\", \n                     penalty = 10, \n                     mixture = 0.1) %>%\n                     set_engine(\"glmnet\")\n\nmodels <- list(LM, XGBOOST, GLMNET)\n\nsuppressWarnings(\n  compare_results(models)\n)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"model_type\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"rmse\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rsq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"mae\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"lm\",\"2\":\"644.5728\",\"3\":\"1.0000000\",\"4\":\"470.6207\"},{\"1\":\"xgboost\",\"2\":\"1249.6365\",\"3\":\"0.6155093\",\"4\":\"865.3932\"},{\"1\":\"glmnet\",\"2\":\"1036.3910\",\"3\":\"1.0000000\",\"4\":\"842.9489\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nSeems like GLM net produces the lowest errors.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}